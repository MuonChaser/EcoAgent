#!/usr/bin/env python3
"""
æ•°æ®å·¥å…·ä½¿ç”¨ç¤ºä¾‹

æœ¬ç¤ºä¾‹å±•ç¤ºå¦‚ä½•:
1. å¯¼å…¥æ•°æ®åˆ°RAGåº“
2. æœç´¢åˆé€‚çš„æ•°æ®é›†
3. é¢„è§ˆå’Œåˆ†ææ•°æ®
4. ä½¿ç”¨DataAnalystAgentï¼ˆå·²é›†æˆæ•°æ®å·¥å…·ï¼‰

ä½¿ç”¨å‰è¯·ç¡®ä¿:
1. å·²å®‰è£…ä¾èµ–: pip install pandas chromadb sentence-transformers
2. data/raw ç›®å½•ä¸­æœ‰æ•°æ®æ–‡ä»¶
"""

import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from loguru import logger

# é…ç½®æ—¥å¿—
logger.remove()
logger.add(
    sys.stderr,
    format="<green>{time:HH:mm:ss}</green> | <level>{level: <8}</level> | <cyan>{message}</cyan>",
    level="INFO"
)


def example_1_import_data():
    """ç¤ºä¾‹1: å¯¼å…¥æ•°æ®åˆ°RAGåº“"""
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹1: å¯¼å…¥æ•°æ®åˆ°RAGåº“")
    print("=" * 60)

    from tools.data_storage import get_data_storage
    from config.config import RAW_DATA_DIR

    # åˆå§‹åŒ–æ•°æ®å­˜å‚¨
    storage = get_data_storage()

    # æ‰«æå¹¶å¯¼å…¥ data/raw ç›®å½•
    print(f"\næ‰«æç›®å½•: {RAW_DATA_DIR}")
    stats = storage.scan_directory(
        directory=str(RAW_DATA_DIR),
        patterns=["*.csv", "*.xlsx"],
        auto_extract=True
    )

    print(f"\nå¯¼å…¥ç»“æœ:")
    print(f"  æ€»æ–‡ä»¶æ•°: {stats['total_files']}")
    print(f"  æˆåŠŸå¯¼å…¥: {stats['imported']}")
    print(f"  è·³è¿‡: {stats['skipped']}")

    # æŸ¥çœ‹ç»Ÿè®¡ä¿¡æ¯
    db_stats = storage.get_statistics()
    print(f"\næ•°æ®åº“ç»Ÿè®¡:")
    print(f"  æ€»æ•°æ®é›†: {db_stats['total_count']}")
    print(f"  æŒ‰ç±»å‹: {db_stats['by_type']}")

    return storage


def example_2_search_datasets(storage=None):
    """ç¤ºä¾‹2: æœç´¢æ•°æ®é›†"""
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹2: æœç´¢æ•°æ®é›†")
    print("=" * 60)

    if storage is None:
        from tools.data_storage import get_data_storage
        storage = get_data_storage()

    # è¯­ä¹‰æœç´¢
    print("\n1. è¯­ä¹‰æœç´¢: 'ä¼ä¸šåˆ›æ–°ç ”å‘æŠ•å…¥'")
    results = storage.search_semantic("ä¼ä¸šåˆ›æ–°ç ”å‘æŠ•å…¥", n_results=3)
    for item in results.items:
        print(f"   [{item.id}] {item.name}")
        print(f"       æè¿°: {item.description[:80]}...")

    # å…³é”®è¯æœç´¢
    print("\n2. å…³é”®è¯æœç´¢: 'DID'")
    results = storage.search_keyword("DID", n_results=3)
    for item in results.items:
        print(f"   [{item.id}] {item.name}")

    # æ··åˆæœç´¢
    print("\n3. æ··åˆæœç´¢: 'é¢æ¿æ•°æ®'")
    results = storage.search_hybrid("é¢æ¿æ•°æ®", n_results=3)
    for item in results.items:
        print(f"   [{item.id}] {item.name}")

    return results


def example_3_preview_data():
    """ç¤ºä¾‹3: é¢„è§ˆæ•°æ®"""
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹3: é¢„è§ˆæ•°æ®")
    print("=" * 60)

    from tools.data_tools import get_data_tools

    # åˆå§‹åŒ–æ•°æ®å·¥å…·
    tools = get_data_tools()

    # æŸ¥æ‰¾æ•°æ®æ–‡ä»¶
    data_file = project_root / "data" / "raw" / "å®è¯è®ºæ–‡æå–ç»“æœ.csv"
    if not data_file.exists():
        print(f"æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_file}")
        return None

    # é¢„è§ˆæ•°æ®
    print(f"\né¢„è§ˆæ–‡ä»¶: {data_file.name}")
    preview = tools.preview_data(str(data_file), n_rows=5)

    print(f"\næ•°æ®æ¦‚å†µ:")
    print(f"  æ€»è¡Œæ•°: {preview.total_rows}")
    print(f"  æ€»åˆ—æ•°: {preview.total_columns}")
    print(f"  åˆ—å: {preview.columns}")
    print(f"  å†…å­˜ä½¿ç”¨: {preview.memory_usage}")

    print(f"\nå‰5è¡Œæ•°æ®:")
    for i, row in enumerate(preview.head[:5]):
        print(f"  {i+1}. {list(row.values())[:3]}...")

    return preview


def example_4_data_statistics():
    """ç¤ºä¾‹4: è·å–æ•°æ®ç»Ÿè®¡"""
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹4: è·å–æ•°æ®ç»Ÿè®¡")
    print("=" * 60)

    from tools.data_tools import get_data_tools

    tools = get_data_tools()

    data_file = project_root / "data" / "raw" / "å®è¯è®ºæ–‡æå–ç»“æœ.csv"
    if not data_file.exists():
        print(f"æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_file}")
        return None

    # è·å–ç»Ÿè®¡ä¿¡æ¯
    print(f"\nåˆ†ææ–‡ä»¶: {data_file.name}")
    stats = tools.get_statistics(str(data_file))

    print(f"\nç¼ºå¤±å€¼ç»Ÿè®¡:")
    for col, missing in list(stats.missing_stats.items())[:5]:
        print(f"  {col}: {missing['missing_count']} ({missing['missing_ratio']*100:.1f}%)")

    print(f"\nåˆ†ç±»å˜é‡ç»Ÿè®¡:")
    for col, cat_stats in list(stats.categorical_stats.items())[:3]:
        print(f"  {col}:")
        print(f"    å”¯ä¸€å€¼æ•°: {cat_stats['unique_count']}")
        print(f"    æœ€å¸¸è§: {cat_stats['most_common']}")

    return stats


def example_5_query_data():
    """ç¤ºä¾‹5: æŸ¥è¯¢æ•°æ®"""
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹5: æŸ¥è¯¢æ•°æ®")
    print("=" * 60)

    from tools.data_tools import get_data_tools

    tools = get_data_tools()

    data_file = project_root / "data" / "raw" / "å®è¯è®ºæ–‡æå–ç»“æœ.csv"
    if not data_file.exists():
        print(f"æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_file}")
        return None

    # æŸ¥è¯¢ç‰¹å®šæ¡ä»¶çš„æ•°æ®
    print(f"\næŸ¥è¯¢åŒ…å«'DID'æ–¹æ³•çš„è®ºæ–‡:")
    try:
        result = tools.query_data(
            str(data_file),
            columns=["æ–‡ç« åç§°", "è®¡é‡æ¨¡å‹ (æ–¹æ³•)"],
            limit=10
        )

        print(f"  æ‰¾åˆ° {result.total_matched} æ¡è®°å½•")
        for row in result.data[:5]:
            print(f"  - {row.get('æ–‡ç« åç§°', 'N/A')[:50]}...")
    except Exception as e:
        print(f"  æŸ¥è¯¢å‡ºé”™: {e}")

    return result


def example_6_data_analyst_agent():
    """ç¤ºä¾‹6: ä½¿ç”¨æ•°æ®åˆ†æAgent"""
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹6: ä½¿ç”¨æ•°æ®åˆ†æAgent (é›†æˆæ•°æ®å·¥å…·)")
    print("=" * 60)

    from agents import DataAnalystAgent

    # åˆå§‹åŒ–Agent
    print("\nåˆå§‹åŒ– DataAnalystAgent...")
    agent = DataAnalystAgent()

    # æœç´¢ç›¸å…³æ•°æ®
    print("\n1. æœç´¢ç›¸å…³æ•°æ®é›†:")
    datasets = agent.search_data("å®è¯ç ”ç©¶æ–¹æ³•", n_results=3)
    for d in datasets:
        print(f"   - {d['name']}: {d.get('row_count', 'N/A')}è¡Œ")

    # å¦‚æœæœ‰æ•°æ®æ–‡ä»¶ï¼Œè¿›è¡Œåˆ†æ
    data_file = project_root / "data" / "raw" / "å®è¯è®ºæ–‡æå–ç»“æœ.csv"
    if data_file.exists():
        print(f"\n2. é¢„è§ˆæ•°æ®é›†:")
        preview = agent.preview_dataset(str(data_file), n_rows=5)
        print(f"   è¡Œæ•°: {preview['total_rows']}")
        print(f"   åˆ—æ•°: {preview['total_columns']}")
        print(f"   åˆ—å: {preview['columns'][:5]}...")

        print(f"\n3. è·å–ç»Ÿè®¡ä¿¡æ¯:")
        stats = agent.get_data_statistics(str(data_file))
        print(f"   ç¼ºå¤±å€¼åˆ—æ•°: {len(stats['missing_stats'])}")

    return agent


def example_7_langchain_tools():
    """ç¤ºä¾‹7: ä½¿ç”¨LangChainå·¥å…·"""
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹7: ä½¿ç”¨LangChainå·¥å…·")
    print("=" * 60)

    from tools.data_tools import get_langchain_data_tools

    # è·å–LangChainæ ¼å¼çš„å·¥å…·
    tools = get_langchain_data_tools()

    print(f"\nå¯ç”¨çš„LangChainå·¥å…·:")
    for tool in tools:
        print(f"  - {tool.name}: {tool.description[:60]}...")

    # è°ƒç”¨å·¥å…·ç¤ºä¾‹
    print(f"\nè°ƒç”¨ search_datasets å·¥å…·:")
    search_tool = tools[0]  # search_datasets
    result = search_tool.invoke({"query": "é¢æ¿æ•°æ®", "n_results": 2})
    print(f"  ç»“æœ: {result[:200]}...")

    return tools


def main():
    """è¿è¡Œæ‰€æœ‰ç¤ºä¾‹"""
    print("\nğŸš€ æ•°æ®å·¥å…·ä½¿ç”¨ç¤ºä¾‹")
    print("=" * 60)

    try:
        # ç¤ºä¾‹1: å¯¼å…¥æ•°æ®
        storage = example_1_import_data()

        # ç¤ºä¾‹2: æœç´¢æ•°æ®é›†
        example_2_search_datasets(storage)

        # ç¤ºä¾‹3: é¢„è§ˆæ•°æ®
        example_3_preview_data()

        # ç¤ºä¾‹4: æ•°æ®ç»Ÿè®¡
        example_4_data_statistics()

        # ç¤ºä¾‹5: æŸ¥è¯¢æ•°æ®
        example_5_query_data()

        # ç¤ºä¾‹6: æ•°æ®åˆ†æAgent (éœ€è¦APIé…ç½®)
        try:
            example_6_data_analyst_agent()
        except Exception as e:
            print(f"\nDataAnalystAgentç¤ºä¾‹è·³è¿‡ (å¯èƒ½ç¼ºå°‘APIé…ç½®): {e}")

        # ç¤ºä¾‹7: LangChainå·¥å…·
        example_7_langchain_tools()

        print("\n" + "=" * 60)
        print("âœ… æ‰€æœ‰ç¤ºä¾‹è¿è¡Œå®Œæˆ!")
        print("=" * 60)

    except Exception as e:
        print(f"\nâŒ ç¤ºä¾‹è¿è¡Œå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
