#!/usr/bin/env python
"""
å®Œæ•´ç ”ç©¶æµç¨‹ - ä»è‡ªç„¶è¯­è¨€è¾“å…¥åˆ°å®Œæ•´æŠ¥å‘Š
ä½¿ç”¨æ–¹å¼: python run_research.py
"""
from orchestrator import ResearchOrchestrator
from loguru import logger
import sys


def main():
    """è¿è¡Œå®Œæ•´çš„ç ”ç©¶æµç¨‹"""
    
    # ç”¨æˆ·è¾“å…¥
    user_input = "æˆ‘æƒ³ç ”ç©¶æ•°å­—åŒ–è½¬å‹å¯¹ä¼ä¸šåˆ›æ–°ç»©æ•ˆçš„å½±å“"
    
    logger.info("=" * 80)
    logger.info("ğŸš€ å¼€å§‹ç»æµå­¦ç ”ç©¶ï¼šAI for Econometrics")
    logger.info("=" * 80)
    logger.info(f"\nğŸ“ ç ”ç©¶é—®é¢˜: {user_input}\n")
    
    # åˆå§‹åŒ–ç¼–æ’å™¨
    orchestrator = ResearchOrchestrator(output_dir="output/research")
    
    try:
        # è¿è¡Œå®Œæ•´æµç¨‹
        logger.info("ğŸ”„ å¯åŠ¨å¤šæ™ºèƒ½ä½“ç ”ç©¶æµç¨‹...\n")
        
        result = orchestrator.run_full_pipeline(
            user_input=user_input,
            enable_steps=[
                "input_parse",    # 0. è¾“å…¥è§£æ
                "literature",     # 1. æ–‡çŒ®æœé›†
                "variable",       # 2. æŒ‡æ ‡è®¾ç½®
                "theory",         # 3. ç†è®ºè®¾ç½®
                "model",          # 4. æ¨¡å‹è®¾è®¡
                # "analysis",     # 5. æ•°æ®åˆ†æï¼ˆéœ€è¦çœŸå®æ•°æ®ï¼‰
                # "report",       # 6. æŠ¥å‘Šæ’°å†™
            ],
            min_papers=8,         # æœé›†è‡³å°‘8ç¯‡æ–‡çŒ®
            enable_review=False,  # æš‚ä¸å¯ç”¨å®¡ç¨¿
        )
        
        # è¾“å‡ºç»“æœæ‘˜è¦
        logger.info("\n" + "=" * 80)
        logger.info("âœ… ç ”ç©¶æµç¨‹å®Œæˆï¼")
        logger.info("=" * 80)
        
        logger.info(f"\nğŸ“Š ç ”ç©¶ä¸»é¢˜: {result.get('research_topic')}")
        
        if "input_parsed_data" in result:
            parsed = result["input_parsed_data"]
            logger.info(f"\nğŸ” æ ¸å¿ƒå˜é‡:")
            logger.info(f"  â€¢ è§£é‡Šå˜é‡(X): {parsed.get('variable_x', {}).get('chinese')}")
            logger.info(f"  â€¢ è¢«è§£é‡Šå˜é‡(Y): {parsed.get('variable_y', {}).get('chinese')}")
        
        if "literature_list" in result:
            lit_count = len(result["literature_list"])
            logger.info(f"\nğŸ“š æ–‡çŒ®æœé›†: {lit_count} ç¯‡æ ¸å¿ƒæ–‡çŒ®")
            
            if lit_count > 0:
                logger.info("\nå‰3ç¯‡æ–‡çŒ®ç¤ºä¾‹:")
                for i, lit in enumerate(result["literature_list"][:3], 1):
                    logger.info(f"  {i}. {lit.get('title', 'N/A')}")
                    logger.info(f"     ä½œè€…: {lit.get('authors', 'N/A')} ({lit.get('year', 'N/A')})")
                    logger.info(f"     æœŸåˆŠ: {lit.get('journal', 'N/A')}\n")
        
        if "variable_system_data" in result:
            var_data = result["variable_system_data"]
            logger.info("ğŸ“ å˜é‡ä½“ç³»è®¾è®¡å®Œæˆ:")
            
            core_vars = var_data.get("core_variables", {})
            x_vars = core_vars.get("explanatory_variable_x", [])
            y_vars = core_vars.get("dependent_variable_y", [])
            control_vars = var_data.get("control_variables", [])
            
            logger.info(f"  â€¢ è§£é‡Šå˜é‡: {len(x_vars)} ä¸ª")
            logger.info(f"  â€¢ è¢«è§£é‡Šå˜é‡: {len(y_vars)} ä¸ª")
            logger.info(f"  â€¢ æ§åˆ¶å˜é‡: {len(control_vars)} ä¸ª")
        
        if "theory_framework_data" in result:
            theory_data = result["theory_framework_data"]
            theories = theory_data.get("theoretical_framework", [])
            hypotheses = theory_data.get("research_hypotheses", [])
            
            logger.info(f"\nğŸ“– ç†è®ºæ¡†æ¶:")
            logger.info(f"  â€¢ ç†è®ºåŸºç¡€: {len(theories)} ä¸ªç†è®º")
            logger.info(f"  â€¢ ç ”ç©¶å‡è®¾: {len(hypotheses)} ä¸ªå‡è®¾")
            
            if hypotheses:
                logger.info("\nå‡è®¾ç¤ºä¾‹:")
                for i, hyp in enumerate(hypotheses[:2], 1):
                    logger.info(f"  H{i}: {hyp.get('hypothesis_content', 'N/A')}")
        
        if "model_design_data" in result:
            model_data = result["model_design_data"]
            logger.info(f"\nğŸ§® è®¡é‡æ¨¡å‹:")
            
            baseline = model_data.get("baseline_model", {})
            logger.info(f"  â€¢ åŸºå‡†æ¨¡å‹: {baseline.get('model_type', 'N/A')}")
            
            mechanism = model_data.get("mechanism_models", [])
            heterogeneity = model_data.get("heterogeneity_models", [])
            robustness = model_data.get("robustness_checks", [])
            
            logger.info(f"  â€¢ æœºåˆ¶æ£€éªŒ: {len(mechanism)} ä¸ªæ¨¡å‹")
            logger.info(f"  â€¢ å¼‚è´¨æ€§åˆ†æ: {len(heterogeneity)} ä¸ªç»´åº¦")
            logger.info(f"  â€¢ ç¨³å¥æ€§æ£€éªŒ: {len(robustness)} ä¸ªæ–¹æ³•")
        
        # è¾“å‡ºæ–‡ä»¶ä½ç½®
        logger.info("\n" + "=" * 80)
        logger.info("ğŸ“ è¾“å‡ºæ–‡ä»¶:")
        logger.info("=" * 80)
        logger.info("  â€¢ å®Œæ•´æŠ¥å‘Š: output/research/report_*.md")
        logger.info("  â€¢ JSONæ•°æ®: output/research/report_*.json")
        logger.info("  â€¢ é˜¶æ®µç»“æœ: output/research/stages/*.json")
        
        logger.success("\nâœ¨ ç ”ç©¶æµç¨‹æˆåŠŸå®Œæˆï¼")
        
        return result
        
    except Exception as e:
        logger.error(f"\nâŒ ç ”ç©¶æµç¨‹å‡ºé”™: {str(e)}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
